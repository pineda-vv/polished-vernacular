{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some helper stuff for tracking performance over the duration of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_model_timestamp(model_type, kfolds, scores, note):\n",
    "    '''\n",
    "    Parameters:\n",
    "    model_type = string description of the model(s) used to make these scores\n",
    "    kfolds     = how many folds in kfold cross validation used\n",
    "    scores     = list of ROC AUC avg scores of models for each class, floats should be like 0.9784\n",
    "    note       = string, whatever is of note about the model, made a change or whatever\n",
    "    \n",
    "    Returns:\n",
    "    None, but writes (appends) a line to scores.txt in the root directory so that progress can be tracked\n",
    "    The format is:\n",
    "            time(s)~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "            \n",
    "    scores.txt is a tilde '~' seperated CSV like:\n",
    "        time~model_type~kfold~avg_roc_auc~toxic_auc~s_toxic_auc~obscene_auc~threat_auc~insult_auc~i_hate_auc~notes\n",
    "        1520303252~0.9794005980274005~note something\n",
    "    '''\n",
    "\n",
    "    out_text = \"{:10.0f}~{:}~{:2d}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:0.8f}~{:}\\n\".format(time.time(), \n",
    "                                             model_type, \n",
    "                                             kfolds, \n",
    "                                             np.mean(scores),\n",
    "                                             scores[0],\n",
    "                                             scores[1],\n",
    "                                             scores[2],\n",
    "                                             scores[3],\n",
    "                                             scores[4],\n",
    "                                             note)\n",
    "    \n",
    "    with open(\"../scores.txt\", 'a') as out_file:\n",
    "        out_file.write(out_text)\n",
    "        \n",
    "        print(\"wrote:\")\n",
    "        print(out_text)\n",
    "        print(\"to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and light processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../data/test.csv').fillna(' ')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize words from both corpuses (corpi?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=5000)    # 10k was initial\n",
    "\n",
    "word_vectorizer.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (159571, 5000)\n",
      "test shape: (153164, 5000)\n"
     ]
    }
   ],
   "source": [
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(\"train shape:\", train_word_features.shape)\n",
    "print(\"test shape:\", test_word_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Spread for class \"toxic\":\n",
      "    0.9653     0.9658     0.9659     0.9670     0.9690     0.9664     0.9637     0.9675     0.9683     0.9695  \n",
      "    CV score for class \"toxic\" is 0.9668\n",
      "\n",
      "CV Spread for class \"severe_toxic\":\n",
      "    0.9824     0.9864     0.9782     0.9862     0.9870     0.9826     0.9879     0.9867     0.9890     0.9883  \n",
      "    CV score for class \"severe_toxic\" is 0.9855\n",
      "\n",
      "CV Spread for class \"obscene\":\n",
      "    0.9866     0.9848     0.9803     0.9841     0.9862     0.9808     0.9844     0.9870     0.9858     0.9834  \n",
      "    CV score for class \"obscene\" is 0.9843\n",
      "\n",
      "CV Spread for class \"threat\":\n",
      "    0.9714     0.9897     0.9928     0.9855     0.9773     0.9851     0.9871     0.9789     0.9871     0.9706  \n",
      "    CV score for class \"threat\" is 0.9825\n",
      "\n",
      "CV Spread for class \"insult\":\n",
      "    0.9769     0.9723     0.9749     0.9718     0.9760     0.9724     0.9743     0.9743     0.9793     0.9766  \n",
      "    CV score for class \"insult\" is 0.9749\n",
      "\n",
      "CV Spread for class \"identity_hate\":\n",
      "    0.9779     0.9676     0.9632     0.9782     0.9629     0.9752     0.9781     0.9787     0.9770     0.9842  \n",
      "    CV score for class \"identity_hate\" is 0.9743\n",
      "\n",
      "Total CV score is 0.9781\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "train_features = train_word_features.copy()\n",
    "\n",
    "# submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1337)\n",
    "    \n",
    "#     results = cross_val_score(classifier, train_features, train_target, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    results = cross_val_score(classifier, train_features, train_target, cv=kfold, scoring='roc_auc')\n",
    "    \n",
    "    print('CV Spread for class \"{}\":'.format(class_name))\n",
    "    for result in results:\n",
    "        print(\"    {:0.4f}\".format(result), end=\" \")\n",
    "        \n",
    "    print(\" \")\n",
    "        \n",
    "    cv_score = np.mean(results)\n",
    "    scores.append(cv_score)\n",
    "    \n",
    "    print('    CV score for class \"{}\" is {:0.4}\\n'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "#     submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {:0.4f}'.format(np.mean(scores)))\n",
    "\n",
    "write_model_timestamp('logistic regression', NUM_FOLDS, scores, \"first model: logistic regression, word to vec max 5k features, kfold=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS          AVG ROC AUC\n",
      "toxic          0.9698\n",
      "severe_toxic   0.9859\n",
      "obscene        0.9854\n",
      "threat         0.9828\n",
      "insult         0.9765\n",
      "identity_hate  0.9761\n"
     ]
    }
   ],
   "source": [
    "print(\"{: <14} {:}\".format(\"CLASS\", \"AVG ROC AUC\"))\n",
    "\n",
    "for item in zip(class_names, scores):\n",
    "    print(\"{: <14} {:0.4f}\".format(item[0], item[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
